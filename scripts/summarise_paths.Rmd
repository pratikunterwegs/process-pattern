---
editor_options: 
  chunk_output_type: console
---

# Summarising agent paths

```{r}
# load libraries
library(data.table)
library(glue)
library(stringr)

# source funs
source("R/fun_dist_disp.R")
source("R/fun_read_pos.R")
source("R/fun_steplength_timescale.R")
```

## List files and read data

needs to be made recursive over dirs.

```{r}
# paths = list.dirs(path = "data", recursive = F)
# paths = paths[grep("sim", paths)]
paths = c(".")

# read data
data = lapply(paths, read_data, gen_start = 50, gen_end = 190)
```

## Get distance and displacement

```{r}
# get distance and displacement
data = lapply(data, function(df) {
  df = df[, list(paths = list(.SD)), by = c("id", "g")]
  df[, c("displacement", "distance") := list(
    vapply(paths, get_displacement, FUN.VALUE = 1.0),
    vapply(paths, get_distance, FUN.VALUE = 1L)
  )]
  
  df
})
```

## Get cumulative distance and avg speed

```{r}
# get fit as list col
data = lapply(data, function(df) {
  assertthat::assert_that(
    "paths" %in% names(df), 
    msg = "paths df listcol missing"
  )
  
  # get cdist data
  df[, cdist_data := lapply(
    paths, get_cumulative_distance
  )]
  
  df[, avg_speed_fit := lapply(cdist_data, get_avg_speed)]
  
  # remove cdist data
  df[, cdist_data := NULL]
  
  df
})
```

## Fit a neg binom distribution to step lengths

```{r}
data = lapply(data, function(df) {
  
  # first subsample and get steplengths
  df[, sl_ := lapply(paths, get_steplengths, tscale = 5)]
  
  # get nbinom fit
  df[, sl_fit := lapply(sl_, fit_sl_dist)]
  
  df[, sl_ := NULL]
  
  df
})
```

## Link landscape metrics

### Read landscape

```{r}
source("R/fun_link_landscape.R")

# read landscape and link to movement
quality_data <- read_landscape(
  "data/data_parameters/kernels32.png"
)
```

### Merge landscape data and path

```{r}
data = lapply(data, function(df) {
  df[, land_summary := lapply(
    paths, get_path_env_summary, land_data = quality_data
  )]
})
```

